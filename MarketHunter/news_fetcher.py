###############################################################################
# FILE: news_fetcher.py - Agregador de Not칤cias Financeiras via RSS
###############################################################################
import feedparser
from datetime import datetime
import time

# RSS Feeds de Not칤cias Financeiras
NEWS_FEEDS = {
    "crypto": [
        {"name": "Cointelegraph", "url": "https://cointelegraph.com/rss", "icon": "游뿣"},
        {"name": "CoinDesk", "url": "https://www.coindesk.com/arc/outboundfeeds/rss/", "icon": "游닗"},
        {"name": "Decrypt", "url": "https://decrypt.co/feed", "icon": "游댏"},
    ],
    "stocks": [
        {"name": "Yahoo Finance", "url": "https://finance.yahoo.com/news/rssindex", "icon": "游늳"},
        {"name": "Investing.com", "url": "https://www.investing.com/rss/news.rss", "icon": "游눷"},
        {"name": "MarketWatch", "url": "https://feeds.marketwatch.com/marketwatch/topstories/", "icon": "游늵"},
    ],
    "brazil": [
        {"name": "InfoMoney", "url": "https://www.infomoney.com.br/feed/", "icon": "游游"},
        {"name": "Valor Econ칪mico", "url": "https://valor.globo.com/rss/valor/", "icon": "游눯"},
    ]
}


def fetch_news_from_feed(feed_url, max_items=10):
    """
    Busca not칤cias de um feed RSS espec칤fico.
    """
    try:
        feed = feedparser.parse(feed_url)
        articles = []
        
        for entry in feed.entries[:max_items]:
            # Tenta extrair a data de publica칞칚o
            published = entry.get('published', entry.get('updated', ''))
            try:
                # Tenta parsear a data
                if hasattr(entry, 'published_parsed') and entry.published_parsed:
                    pub_date = datetime(*entry.published_parsed[:6])
                    time_ago = format_time_ago(pub_date)
                else:
                    time_ago = published[:20] if published else "Recente"
            except:
                time_ago = "Recente"
            
            articles.append({
                'title': entry.get('title', 'Sem t칤tulo'),
                'link': entry.get('link', '#'),
                'summary': clean_summary(entry.get('summary', entry.get('description', ''))),
                'published': time_ago,
                'source': feed.feed.get('title', 'Fonte desconhecida')
            })
        
        return articles
    except Exception as e:
        print(f"Erro ao buscar feed {feed_url}: {e}")
        return []


def fetch_all_news(category="crypto", max_per_source=5):
    """
    Busca not칤cias de todas as fontes de uma categoria.
    """
    feeds = NEWS_FEEDS.get(category, NEWS_FEEDS["crypto"])
    all_news = []
    
    for feed_info in feeds:
        articles = fetch_news_from_feed(feed_info['url'], max_per_source)
        for article in articles:
            article['source_name'] = feed_info['name']
            article['icon'] = feed_info['icon']
        all_news.extend(articles)
    
    return all_news


def clean_summary(text):
    """Remove tags HTML do resumo."""
    import re
    clean = re.sub(r'<[^>]+>', '', text)
    return clean[:300] + "..." if len(clean) > 300 else clean


def format_time_ago(dt):
    """Formata a data como 'h치 X minutos/horas'."""
    now = datetime.now()
    diff = now - dt
    
    if diff.days > 0:
        return f"h치 {diff.days} dia{'s' if diff.days > 1 else ''}"
    elif diff.seconds >= 3600:
        hours = diff.seconds // 3600
        return f"h치 {hours} hora{'s' if hours > 1 else ''}"
    elif diff.seconds >= 60:
        minutes = diff.seconds // 60
        return f"h치 {minutes} min"
    else:
        return "agora"


def get_trending_topics(news_list):
    """
    Extrai os t칩picos mais mencionados nas not칤cias.
    """
    from collections import Counter
    
    # Palavras-chave de interesse
    keywords = ['bitcoin', 'btc', 'ethereum', 'eth', 'solana', 'sol', 'xrp', 'bnb',
                'fed', 'trump', 'sec', 'etf', 'bull', 'bear', 'alta', 'queda',
                'ibovespa', 'd칩lar', 'petrobras', 'vale', 'selic', 'infla칞칚o']
    
    word_count = Counter()
    
    for news in news_list:
        text = (news.get('title', '') + ' ' + news.get('summary', '')).lower()
        for keyword in keywords:
            if keyword in text:
                word_count[keyword] += 1
    
    return word_count.most_common(5)


if __name__ == "__main__":
    print("游댍 Testando agregador de not칤cias...")
    
    print("\n游닗 NOT칈CIAS CRYPTO:")
    crypto_news = fetch_all_news("crypto", max_per_source=3)
    for news in crypto_news[:5]:
        print(f"  {news['icon']} [{news['source_name']}] {news['title'][:60]}...")
    
    print("\n游늳 NOT칈CIAS STOCKS:")
    stock_news = fetch_all_news("stocks", max_per_source=3)
    for news in stock_news[:5]:
        print(f"  {news['icon']} [{news['source_name']}] {news['title'][:60]}...")
    
    print("\n游游 NOT칈CIAS BRASIL:")
    br_news = fetch_all_news("brazil", max_per_source=3)
    for news in br_news[:5]:
        print(f"  {news['icon']} [{news['source_name']}] {news['title'][:60]}...")
